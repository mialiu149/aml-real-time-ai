{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to build, train, evaluate and deploy a model running on FPGA. Only Windows is supported. We use TensorFlow and Keras to build our model. We are going to use transfer learning, with ResNet50 as a featurizer. We don't use the last layer of ResNet50 in this case and instead add and train our own classification layer.\n",
    "\n",
    "We will use the Kaggle Cats and Dogs dataset to train the classifier. The data set can be downloaded [here](https://www.microsoft.com/en-us/download/details.aspx?id=54765). Download the zip and extract to a directory named 'catsanddogs' under your user directory (\"~/catsanddogs\").\n",
    "\n",
    "Please set up your environment as described in the [quick start](00_QuickStart.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /Users/mialiu/anaconda3/envs/amlrealtimeai/lib/python3.6/site-packages (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /Users/mialiu/anaconda3/envs/amlrealtimeai/lib/python3.6/site-packages (from h5py) (1.15.1)\n",
      "Requirement already satisfied: six in /Users/mialiu/anaconda3/envs/amlrealtimeai/lib/python3.6/site-packages (from h5py) (1.11.0)\n",
      "\u001b[31mtwisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-fft 1.0.4 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import amlrealtimeai\n",
    "from amlrealtimeai import resnet50\n",
    "import sys\n",
    "!{sys.executable} -m pip install h5py\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction\n",
    "Load the files we are going to use for training and testing. By default this notebook uses only a very small subset of the Cats and Dogs dataset. That makes it run quickly, but doesn't create a very accurate classifier. You can improve the classifier by using more of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to preprocess the input file to get it into the form expected by ResNet50. We've provided a default implementation of the preprocessing that you can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Input images as a two-dimensional tensor containing an arbitrary number of images represented a strings\n",
    "import amlrealtimeai.resnet50.utils\n",
    "#datadir = os.path.expanduser(\"/Users/mialiu/Downloads/\")\n",
    "in_images = tf.placeholder(tf.string)\n",
    "image_tensors = resnet50.utils.preprocess_array(in_images)\n",
    "image_tensors = tf.placeholder(tf.int32,shape=(None,224, 224, 3))\n",
    "#print(image_tensors.shape)\n",
    "print(type(image_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you would like to customize the preprocessing, you can write your own preprocessor using TensorFlow operations.\n",
    "\n",
    "The input to the classifier we are training is the set of features produced by ResNet50. To train the classifier we need to \n",
    "featurize the images using resnet50. We do this using a featurizer running on FPGA. You can also run the featurizer locally on CPU or GPU.\n",
    "\n",
    "Go to our [GitHub repo](https://aka.ms/aml-real-time-ai) \"docs\" folder to learn how to create a Model Management Account and find the required information below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.6-rc\n"
     ]
    }
   ],
   "source": [
    "subscription_id = \"80defacd-509e-410c-9812-6e52ed6a0016\"\n",
    "resource_group = \"CMS_FPGA_Resources\"\n",
    "model_management_account = \"CMS_FPGA_1\"\n",
    "\n",
    "from amlrealtimeai.resnet50.model import RemoteQuantizedResNet50\n",
    "model_path = os.path.expanduser('~/models')\n",
    "featurizer = RemoteQuantizedResNet50(subscription_id, resource_group, model_management_account, model_path)\n",
    "print(featurizer.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling import_graph_def on the featurizer will create a service that runs the featurizer on FPGA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model resnet50-1.1.6-rc-model\n",
      "Successfully registered model resnet50-1.1.6-rc-model\n",
      "Creating service featurizer-service-08cdb9\n",
      ". . . . . . . . . \n",
      "Successfully created service featurizer-service-08cdb9\n"
     ]
    }
   ],
   "source": [
    "featurizer.import_graph_def(include_top=False, input_tensor=image_tensors)\n",
    "features = featurizer.featurizer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-compute features\n",
    "Load the data set and compute the features. These can be precomputed because they don't change during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [06:59,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 1, 1, 2048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from a file.\"\"\"\n",
    "    for i in range(0, l.shape[0], n):\n",
    "    #for i in range(0, 50, n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def read_files(files):\n",
    "    contents = []\n",
    "    for path in files:\n",
    "        with open(path, 'rb') as f:\n",
    "            contents.append(f.read())\n",
    "    return contents\n",
    "        \n",
    "feature_list = []\n",
    "f = h5py.File(\"/Users/mialiu/Downloads/jetImage_1k.h5\",'r')\n",
    "images = f['jetImagePt']\n",
    "with tf.Session() as sess:\n",
    "    for chunk in tqdm(chunks(images,10)):\n",
    "        onechan = chunk\n",
    "        image = np.stack([onechan, onechan, onechan],axis=-1)# \n",
    "        result= sess.run([features],feed_dict={image_tensors:image}) # \n",
    "        feature_list.extend(result[0])\n",
    "feature_results = np.array(feature_list)\n",
    "print(feature_results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"jets\": shape (1000, 60), type \"<f8\">"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['jetImageE']\n",
    "f['jets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove remote service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting service 8d85645de0ca4618b228a3733d9cf23c\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Deleted service 8d85645de0ca4618b228a3733d9cf23c\n",
      "Deleting model cdcb37b6ee0a404ea4dcf98147a6e9f7\n",
      "Deleted model cdcb37b6ee0a404ea4dcf98147a6e9f7\n"
     ]
    }
   ],
   "source": [
    "featurizer.cleanup_remote_service()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add and Train the classifier\n",
    "We use Keras to define and train a simple classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense, Flatten\n",
    "from keras import optimizers\n",
    "\n",
    "FC_SIZE = 1024\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.2, input_shape=(1, 1, 2048,)))\n",
    "model.add(Dense(FC_SIZE, activation='relu', input_dim=(1, 1, 2048,)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(NUM_CLASSES, activation='sigmoid', input_dim=FC_SIZE))\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(lr=1e-4,momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "(749, 1, 1, 2048) (250, 1, 1, 2048) (749, 5) (250, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#onehot_labels = np.array([[0,1] if i else [1,0] for i in labels])\n",
    "onehot_labels = np.array([f[\"jets\"][i][-6:-1] for i in range(0,f[\"jets\"].shape[0]-1)])\n",
    "print(onehot_labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_results, onehot_labels, random_state=42, shuffle=True)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "749/749 [==============================] - 2s 2ms/step - loss: 0.5845 - acc: 0.7268\n",
      "Epoch 2/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.5107 - acc: 0.7995\n",
      "Epoch 3/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.5023 - acc: 0.8000\n",
      "Epoch 4/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.5039 - acc: 0.8000\n",
      "Epoch 5/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.5034 - acc: 0.8000\n",
      "Epoch 6/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.5022 - acc: 0.8000\n",
      "Epoch 7/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.5019 - acc: 0.8000\n",
      "Epoch 8/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.4987 - acc: 0.8000\n",
      "Epoch 9/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.5006 - acc: 0.7997\n",
      "Epoch 10/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.4979 - acc: 0.8000\n",
      "Epoch 11/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.4981 - acc: 0.8000\n",
      "Epoch 12/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.4980 - acc: 0.8000\n",
      "Epoch 13/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.4991 - acc: 0.8000\n",
      "Epoch 14/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.4984 - acc: 0.8000\n",
      "Epoch 15/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.4988 - acc: 0.8000\n",
      "Epoch 16/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.4984 - acc: 0.8000\n",
      "Epoch 17/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.5002 - acc: 0.8000\n",
      "Epoch 18/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.4979 - acc: 0.8000\n",
      "Epoch 19/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.4971 - acc: 0.8000\n",
      "Epoch 20/20\n",
      "749/749 [==============================] - 1s 2ms/step - loss: 0.4985 - acc: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2c42ef28>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Classifier\n",
    "Let's test the classifier and see how well it does. Since we only trained on a few images, we are not expecting to win a Kaggle competition, but it will likely get most of the images correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28835747 0.16109025 0.18349946 0.16877846 0.24602272]\n",
      " [0.29066697 0.16372655 0.17695418 0.17001767 0.25235024]\n",
      " [0.2926258  0.16979125 0.17431323 0.16925006 0.2504912 ]\n",
      " ...\n",
      " [0.28764048 0.16268021 0.17318466 0.17499971 0.2502044 ]\n",
      " [0.29237282 0.16624995 0.17816249 0.17222983 0.25339085]\n",
      " [0.2910867  0.15479662 0.18316478 0.17671031 0.24936089]]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 2 0 1 1 0 3 3 4 3 0 1 4 1 3 2 0 4 2 3 2 0 1 4 4 1 0 2 3 2 0 0 1 4 3 4 1\n",
      " 4 1 0 1 1 0 0 2 1 2 0 0 0 3 4 4 4 2 3 2 1 0 1 4 0 2 2 1 0 4 3 0 1 4 0 1 3\n",
      " 4 0 4 2 4 1 0 4 1 1 4 0 0 0 2 4 3 2 0 4 4 1 3 0 1 2 1 3 3 1 4 4 4 1 4 2 1\n",
      " 4 0 0 1 4 1 2 3 3 4 4 4 0 0 2 2 0 4 4 2 1 2 0 0 1 0 2 4 0 4 2 3 4 0 1 4 3\n",
      " 1 1 4 3 2 0 0 2 4 4 0 1 1 1 4 0 4 3 4 4 4 4 4 2 1 3 0 0 4 0 2 3 0 4 0 4 1\n",
      " 3 4 2 4 2 3 1 0 1 2 4 1 3 3 1 4 3 4 0 3 1 3 4 2 3 2 3 0 1 3 4 4 4 3 3 4 3\n",
      " 0 3 1 0 2 3 1 4 2 2 3 3 4 3 3 0 4 3 2 2 2 4 4 0 3 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "y_probs = model.predict(X_test)\n",
    "print(y_probs)\n",
    "print(y_test)\n",
    "y_prob_max = np.argmax(y_probs, 1)\n",
    "y_test_max = np.argmax(y_test, 1)\n",
    "print(y_prob_max)\n",
    "print(y_test_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-1d91cf526924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mcm_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prob_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcm_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-1d91cf526924>\u001b[0m in \u001b[0;36mclassification_metrics\u001b[0;34m(y_true, y_pred, y_prob)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcm_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Precision'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mcm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Recall'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'F1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amlrealtimeai/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1259\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1262\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amlrealtimeai/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0;32m-> 1040\u001b[0;31m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[1;32m   1041\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import itertools\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# compute a bunch of classification metrics \n",
    "def classification_metrics(y_true, y_pred, y_prob):\n",
    "    cm_dict = {}\n",
    "    cm_dict['Accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    cm_dict['Precision'] =  precision_score(y_true, y_pred)\n",
    "    cm_dict['Recall'] =  recall_score(y_true, y_pred)\n",
    "    cm_dict['F1'] =  f1_score(y_true, y_pred) \n",
    "    cm_dict['AUC'] = roc_auc_score(y_true, y_prob[:,0])\n",
    "    cm_dict['Confusion Matrix'] = confusion_matrix(y_true, y_pred).tolist()\n",
    "    return cm_dict\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"Plots a confusion matrix.\n",
    "    Source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    New BSD License - see appendix\n",
    "    \"\"\"\n",
    "    cm_max = cm.max()\n",
    "    cm_min = cm.min()\n",
    "    if cm_min > 0: cm_min = 0\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm_max = 1\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    thresh = cm_max / 2.\n",
    "    plt.clim(cm_min, cm_max)\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i,\n",
    "                 round(cm[i, j], 3),  # round to 3 decimals if they are float\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "cm_dict = classification_metrics(y_test_max, y_prob_max, y_probs)\n",
    "for m in cm_dict:\n",
    "    print(m, cm_dict[m])\n",
    "cm = np.asarray(cm_dict['Confusion Matrix'])\n",
    "plot_confusion_matrix(cm, ['fail','pass'], normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service Definition\n",
    "Like in the QuickStart notebook our service definition pipeline consists of three stages. Here we use the Keras classifier as the final stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 0 variables.\n",
      "Converted 0 variables to const ops.\n",
      "INFO:tensorflow:Froze 4 variables.\n",
      "Converted 4 variables to const ops.\n",
      "/Users/mialiu/Downloads/kagglecatsanddogs_3367a/save/service_def\n"
     ]
    }
   ],
   "source": [
    "from amlrealtimeai.pipeline import ServiceDefinition, TensorflowStage, BrainWaveStage, KerasStage\n",
    "\n",
    "service_def = ServiceDefinition()\n",
    "service_def.pipeline.append(TensorflowStage(tf.Session(), in_images, image_tensors))\n",
    "service_def.pipeline.append(BrainWaveStage(featurizer))\n",
    "service_def.pipeline.append(KerasStage(model))\n",
    "\n",
    "service_def_path = os.path.join(datadir, 'save', 'service_def')\n",
    "service_def.save(service_def_path)\n",
    "print(service_def_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amlrealtimeai import DeploymentClient\n",
    "\n",
    "model_name = \"catsanddogs-model\"\n",
    "service_name = \"modelbuild-service\"\n",
    "\n",
    "deployment_client = DeploymentClient(subscription_id, resource_group, model_management_account)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time the code below runs it will create a new service running your model. If you want to change the model you can make changes above in this notebook and save a new service definition. Then this code will update the running service in place to run the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model catsanddogs-model\n",
      "Successfully registered model catsanddogs-model\n"
     ]
    }
   ],
   "source": [
    "service = deployment_client.get_service_by_name(service_name)\n",
    "model_id = deployment_client.register_model(model_name, service_def_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service modelbuild-service\n",
      ". . . . . . . . . \n",
      "Successfully created service modelbuild-service\n"
     ]
    }
   ],
   "source": [
    "if(service is None):\n",
    "    service = deployment_client.create_service(service_name, model_id)    \n",
    "else:\n",
    "    service = deployment_client.update_service(service.id, model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The service is now running in Azure and ready to serve requests. We can check the address and port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.121.62.234:80\n"
     ]
    }
   ],
   "source": [
    "print(service.ipAddress + ':' + str(service.port))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client\n",
    "There is a simple test client at amlrealtimeai.PredictionClient which can be used for testing. We'll use this client to score an image with our new service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amlrealtimeai import PredictionClient\n",
    "client = PredictionClient(service.ipAddress, service.port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can adapt the client [code](../../pythonlib/amlrealtimeai/client.py) to meet your needs. There is also an example C# [client](../../sample-clients/csharp).\n",
    "\n",
    "The service provides an API that is compatible with TensorFlow Serving. There are instructions to download a sample client [here](https://www.tensorflow.org/serving/setup)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request\n",
    "Let's see how our service does on a few images. It may get a few wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATS\n",
      "CORRECT [0.4911853 0.4856984]\n",
      "CORRECT [0.62519485 0.3544419 ]\n",
      "CORRECT [0.5897753  0.14872892]\n",
      "CORRECT [0.5802131  0.35239896]\n",
      "CORRECT [0.66824925 0.15894377]\n",
      "CORRECT [0.76457125 0.13966438]\n",
      "CORRECT [0.8094868 0.3515233]\n",
      "CORRECT [0.72812706 0.20976284]\n",
      "DOGS\n",
      "CORRECT [0.39778802 0.49379167]\n",
      "CORRECT [0.48429555 0.6952659 ]\n",
      "CORRECT [0.25493044 0.8189195 ]\n",
      "CORRECT [0.31072652 0.62333775]\n",
      "CORRECT [0.2599125 0.6224645]\n",
      "CORRECT [0.32086092 0.6722173 ]\n",
      "CORRECT [0.12503223 0.763471  ]\n",
      "CORRECT [0.40614098 0.40969202]\n"
     ]
    }
   ],
   "source": [
    "# Specify an image to classify\n",
    "print('CATS')\n",
    "for image_file in cat_files[:8]:\n",
    "    results = client.score_image(image_file)\n",
    "    result = 'CORRECT ' if results[0] > results[1] else 'WRONG '\n",
    "    print(result + str(results))\n",
    "print('DOGS')\n",
    "for image_file in dog_files[:8]:\n",
    "    results = client.score_image(image_file)\n",
    "    result = 'CORRECT ' if results[1] > results[0] else 'WRONG '\n",
    "    print(result + str(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "Run the cell below to delete your service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4c909171960244e4830b9bce837ba9c3\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "eff4736bda5b4daa907bd025f13c3b53\n",
      "a9e748ce56184c53a41ee42382432ed0\n"
     ]
    }
   ],
   "source": [
    "services = deployment_client.list_services()\n",
    "\n",
    "for service in filter(lambda x: x.name == service_name, services):\n",
    "    print(service.id)\n",
    "    deployment_client.delete_service(service.id)\n",
    "    \n",
    "models = deployment_client.list_models()\n",
    "\n",
    "for model in filter(lambda x: x.name == model_name, models):\n",
    "    print(model.id)\n",
    "    deployment_client.delete_model(model.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "License for plot_confusion_matrix:\n",
    "\n",
    "New BSD License\n",
    "\n",
    "Copyright (c) 2007–2018 The scikit-learn developers.\n",
    "All rights reserved.\n",
    "\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without\n",
    "modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "  a. Redistributions of source code must retain the above copyright notice,\n",
    "     this list of conditions and the following disclaimer.\n",
    "  b. Redistributions in binary form must reproduce the above copyright\n",
    "     notice, this list of conditions and the following disclaimer in the\n",
    "     documentation and/or other materials provided with the distribution.\n",
    "  c. Neither the name of the Scikit-learn Developers  nor the names of\n",
    "     its contributors may be used to endorse or promote products\n",
    "     derived from this software without specific prior written\n",
    "     permission. \n",
    "\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
    "ARE DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE FOR\n",
    "ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n",
    "LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n",
    "OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH\n",
    "DAMAGE.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
